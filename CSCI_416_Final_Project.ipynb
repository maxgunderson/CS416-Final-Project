{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KVOHOwpor0Gn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# sklearn load_boston no longer works\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NDcPHwEFr7jm",
        "outputId": "7238e7d4-7f41-466d-9c53-136a28f0317a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  MEDV  \n",
              "0     15.3  396.90   4.98  24.0  \n",
              "1     17.8  396.90   9.14  21.6  \n",
              "2     17.8  392.83   4.03  34.7  \n",
              "3     18.7  394.63   2.94  33.4  \n",
              "4     18.7  396.90   5.33  36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcd49197-1d62-4b94-9452-5dc09db8923a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcd49197-1d62-4b94-9452-5dc09db8923a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcd49197-1d62-4b94-9452-5dc09db8923a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcd49197-1d62-4b94-9452-5dc09db8923a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5cc167e-15c1-478e-a582-38487c594d07\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5cc167e-15c1-478e-a582-38487c594d07')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5cc167e-15c1-478e-a582-38487c594d07 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_values",
              "summary": "{\n  \"name\": \"data_values\",\n  \"rows\": 506,\n  \"fields\": [\n    {\n      \"column\": \"CRIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.601545105332487,\n        \"min\": 0.00632,\n        \"max\": 88.9762,\n        \"num_unique_values\": 504,\n        \"samples\": [\n          0.09178,\n          0.05644,\n          0.10574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.322452994515036,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          25.0,\n          30.0,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INDUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.8603529408975845,\n        \"min\": 0.46,\n        \"max\": 27.74,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          8.14,\n          1.47,\n          1.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CHAS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2539940413404118,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NOX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11587767566755611,\n        \"min\": 0.385,\n        \"max\": 0.871,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          0.401,\n          0.538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7026171434153237,\n        \"min\": 3.561,\n        \"max\": 8.78,\n        \"num_unique_values\": 446,\n        \"samples\": [\n          6.849,\n          4.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.148861406903638,\n        \"min\": 2.9,\n        \"max\": 100.0,\n        \"num_unique_values\": 356,\n        \"samples\": [\n          51.8,\n          33.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DIS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1057101266276104,\n        \"min\": 1.1296,\n        \"max\": 12.1265,\n        \"num_unique_values\": 412,\n        \"samples\": [\n          2.2955,\n          4.2515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.707259384239377,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168.53711605495926,\n        \"min\": 187.0,\n        \"max\": 711.0,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          370.0,\n          666.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PTRATIO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.164945523714446,\n        \"min\": 12.6,\n        \"max\": 22.0,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          19.6,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91.29486438415779,\n        \"min\": 0.32,\n        \"max\": 396.9,\n        \"num_unique_values\": 357,\n        \"samples\": [\n          396.24,\n          395.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSTAT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.141061511348571,\n        \"min\": 1.73,\n        \"max\": 37.97,\n        \"num_unique_values\": 455,\n        \"samples\": [\n          6.15,\n          4.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEDV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.19710408737982,\n        \"min\": 5.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          14.1,\n          22.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# make the data and target np arrays into a dataframe with appropriate column names\n",
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "data_values = pd.DataFrame(data, columns=column_names)\n",
        "data_values['MEDV'] = target\n",
        "data_values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-H6Ht-18c9nH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7pDW_5Oznmjt"
      },
      "outputs": [],
      "source": [
        "# declaring the features and target and scaling features\n",
        "X = data_values[column_names]\n",
        "y = data_values['MEDV']\n",
        "\n",
        "scale = StandardScaler()\n",
        "\n",
        "X = scale.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rfDJ9eplpQWR"
      },
      "outputs": [],
      "source": [
        "# creating testing and training splits\n",
        "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KicCQ8OUwB1w"
      },
      "outputs": [],
      "source": [
        "# helper function that will declare the model with the desired parameters, fit it, and print the mse\n",
        "def get_mse(learning_rate, regularization):\n",
        "  sgdr = SGDRegressor(eta0=learning_rate, penalty=regularization)\n",
        "  sgdr.fit(X_train, y_train)\n",
        "  y_pred = sgdr.predict(X_test)\n",
        "  mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
        "  print(f'Mean squared error (L{regularization[1:]} regularization & {learning_rate} learning rate):', mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgWWzvukqxGb",
        "outputId": "0edfab66-b16d-48ca-d736-1048bcb4986e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error (L1 regularization & 0.001 learning rate): 29.728221011477512\n",
            "Mean squared error (L1 regularization & 0.01 learning rate): 29.70260295088632\n",
            "Mean squared error (L1 regularization & 0.1 learning rate): 36.825276940921206\n"
          ]
        }
      ],
      "source": [
        "# we want to test different learning rates (0.001, 0.01, 0.1) with both L1 and L2 regularization\n",
        "l1 = 'l1'\n",
        "# L1 regularization with eta = 0.001\n",
        "get_mse(0.001, l1)\n",
        "# L1 regularization with eta = 0.01\n",
        "get_mse(0.01, l1)\n",
        "# L1 regularization with eta = 0.1\n",
        "get_mse(0.1, l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWZxTtpcw65t",
        "outputId": "cbbdf0d3-e36e-4b13-91e5-58e1cdad871e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error (L2 regularization & 0.001 learning rate): 29.720754345653738\n",
            "Mean squared error (L2 regularization & 0.01 learning rate): 29.510925194330973\n",
            "Mean squared error (L2 regularization & 0.1 learning rate): 31.20819687675843\n"
          ]
        }
      ],
      "source": [
        "# now do the above process with l2 regularization\n",
        "l2 = 'l2'\n",
        "# L2 regularization with eta = 0.001\n",
        "get_mse(0.001, l2)\n",
        "# L2 regularization with eta = 0.01\n",
        "get_mse(0.01, l2)\n",
        "# L2 regularization with eta = 0.1\n",
        "get_mse(0.1, l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iDDoHtxrueJz"
      },
      "outputs": [],
      "source": [
        "# helper function that will fit each model 100 times and average the mse over those 100 times to get\n",
        "# a better idea of which model performs better/worse on average\n",
        "import statistics\n",
        "\n",
        "def get_avg_mse(model):\n",
        "  errors = []\n",
        "  for i in range(100):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
        "    errors.append(mse)\n",
        "  return statistics.mean(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFFc-jg9ue-l",
        "outputId": "8ad27104-47e9-4e0a-e406-8375ba532d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.001: 29.71953396749659\n",
            "The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.01: 29.584702813214403\n",
            "The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.1: 30.52072472173034\n",
            "The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.001: 29.719923937469872\n",
            "The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.01: 29.572993121427686\n",
            "The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.1: 30.952393689622642\n"
          ]
        }
      ],
      "source": [
        "# now each of those regularization/learning rate combos will be run 100 times and the errors of the\n",
        "# trials will be averaged to determine more accurate error values\n",
        "model = SGDRegressor(eta0=0.001, penalty='l1')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.001:', avg_mse)\n",
        "model = SGDRegressor(eta0=0.01, penalty='l1')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.01:', avg_mse)\n",
        "model = SGDRegressor(eta0=0.1, penalty='l1')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L1 regulzarization and a learning rate of 0.1:', avg_mse)\n",
        "model = SGDRegressor(eta0=0.001, penalty='l2')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.001:', avg_mse)\n",
        "model = SGDRegressor(eta0=0.01, penalty='l2')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.01:', avg_mse)\n",
        "model = SGDRegressor(eta0=0.1, penalty='l2')\n",
        "avg_mse = get_avg_mse(model)\n",
        "print('The average mse after 100 trials for SGD regression with L2 regulzarization and a learning rate of 0.1:', avg_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6jKPYR5BvzTq"
      },
      "outputs": [],
      "source": [
        "# now train AdaBoost Classifier on the data and compare the results\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C0svNaTlvzTq"
      },
      "outputs": [],
      "source": [
        "# declare decision stumps to use in AdaBoost\n",
        "stump = DecisionTreeRegressor(max_depth=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "s53DUfwmvzTr"
      },
      "outputs": [],
      "source": [
        "# declare AdaBoost model\n",
        "adaboost = AdaBoostRegressor(estimator=stump, n_estimators=5000, learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itD7yq9dvzTr",
        "outputId": "e4c682fe-a7c4-4b1e-e572-1460831b1c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error (AdaBoost Regression with decision stumps): 40.51757812866384\n"
          ]
        }
      ],
      "source": [
        "# get predictions from AdaBoost model and get MSE to compare with linear regression models\n",
        "adaboost.fit(X_train, y_train)\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
        "# using AdaBoost with strict decision stumps (max_depth = 1) performs poorly as the data has too\n",
        "# many features and the stumps are not able to provide enough information\n",
        "print('Mean squared error (AdaBoost Regression with decision stumps):', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SODwaOd0vqKE",
        "outputId": "e6c3ae82-666d-4bf8-dd1e-58c318e3bd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average mse after 100 trials for AdaBoost regression with decision stumps: 41.261088556397596\n"
          ]
        }
      ],
      "source": [
        "# get the average mse after 100 trials\n",
        "print('The average mse after 100 trials for AdaBoost regression with decision stumps:', get_avg_mse(adaboost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnuxhafivzTr",
        "outputId": "1fcd51e1-5ac3-4edb-ae24-6c2a86307f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error (AdaBoost Regression with decision trees): 8.55864498197303\n"
          ]
        }
      ],
      "source": [
        "# try AdaBoost with more complex base estimator\n",
        "tree = DecisionTreeRegressor(max_depth=4)\n",
        "adaboost = AdaBoostRegressor(estimator=tree, n_estimators=5000, learning_rate=0.1)\n",
        "\n",
        "adaboost.fit(X_train, y_train)\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
        "# using AdaBoost with strict decision trees allow AdaBoost to gather more information\n",
        "# and thus make better predictions\n",
        "print('Mean squared error (AdaBoost Regression with decision trees):', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLd_90Fjv9Vp",
        "outputId": "4e7edda6-5c48-470f-ea05-b519a61895be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average mse after 100 trials for AdaBoost regression with decision trees: 8.521003392667275\n"
          ]
        }
      ],
      "source": [
        "# get the average mse after 100 trials\n",
        "print('The average mse after 100 trials for AdaBoost regression with decision trees:', get_avg_mse(adaboost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AxC9jSlSvzTr"
      },
      "outputs": [],
      "source": [
        "# now try training a neural network to perform the regression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, BatchNormalization\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Pth36OjUwcEn"
      },
      "outputs": [],
      "source": [
        "# define the neural network and add an input + hidden layers\n",
        "nn = Sequential()\n",
        "nn.add(InputLayer((X_train.shape[1],)))\n",
        "# add a lay with regularization\n",
        "nn.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
        "# Batch normalization to normalize the outputs from each hidden layer before passing them along\n",
        "# Batch normalization ensures that the data distribution remains consistent\n",
        "nn.add(BatchNormalization())\n",
        "nn.add(Dense(8, activation='relu'))\n",
        "nn.add(BatchNormalization())\n",
        "# linear activation function for output layer in regression\n",
        "nn.add(Dense(1, activation='linear'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap0EkxOwzQaW",
        "outputId": "1c1e75e2-4419-421c-9548-8da00aeb3d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 578.0140 - mse: 576.5538 - val_loss: 492.7515 - val_mse: 491.2986\n",
            "Epoch 2/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 532.5339 - mse: 531.0824 - val_loss: 489.7682 - val_mse: 488.3226\n",
            "Epoch 3/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 590.7202 - mse: 589.2768 - val_loss: 482.1985 - val_mse: 480.7606\n",
            "Epoch 4/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 584.5072 - mse: 583.0696 - val_loss: 474.2986 - val_mse: 472.8632\n",
            "Epoch 5/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 517.1910 - mse: 515.7567 - val_loss: 463.7989 - val_mse: 462.3683\n",
            "Epoch 6/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 508.9358 - mse: 507.5065 - val_loss: 456.2345 - val_mse: 454.8092\n",
            "Epoch 7/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 497.9839 - mse: 496.5595 - val_loss: 446.0112 - val_mse: 444.5898\n",
            "Epoch 8/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 497.4680 - mse: 496.0481 - val_loss: 432.5339 - val_mse: 431.1174\n",
            "Epoch 9/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 453.7187 - mse: 452.3026 - val_loss: 417.1557 - val_mse: 415.7433\n",
            "Epoch 10/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 454.6683 - mse: 453.2575 - val_loss: 398.1502 - val_mse: 396.7447\n",
            "Epoch 11/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 409.4977 - mse: 408.0945 - val_loss: 376.6411 - val_mse: 375.2444\n",
            "Epoch 12/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 341.7850 - mse: 340.3899 - val_loss: 361.8441 - val_mse: 360.4548\n",
            "Epoch 13/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 329.5027 - mse: 328.1162 - val_loss: 337.1939 - val_mse: 335.8129\n",
            "Epoch 14/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 314.7076 - mse: 313.3287 - val_loss: 314.5324 - val_mse: 313.1612\n",
            "Epoch 15/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 326.5239 - mse: 325.1544 - val_loss: 290.9322 - val_mse: 289.5685\n",
            "Epoch 16/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 319.1310 - mse: 317.7693 - val_loss: 265.7258 - val_mse: 264.3710\n",
            "Epoch 17/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271.4688 - mse: 270.1163 - val_loss: 239.3885 - val_mse: 238.0411\n",
            "Epoch 18/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271.3291 - mse: 269.9825 - val_loss: 223.6454 - val_mse: 222.3017\n",
            "Epoch 19/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 193.2426 - mse: 191.9000 - val_loss: 198.1207 - val_mse: 196.7826\n",
            "Epoch 20/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 192.1070 - mse: 190.7712 - val_loss: 177.6647 - val_mse: 176.3340\n",
            "Epoch 21/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153.6658 - mse: 152.3354 - val_loss: 158.7148 - val_mse: 157.3857\n",
            "Epoch 22/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145.5036 - mse: 144.1751 - val_loss: 139.3535 - val_mse: 138.0277\n",
            "Epoch 23/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135.7118 - mse: 134.3866 - val_loss: 121.7601 - val_mse: 120.4370\n",
            "Epoch 24/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.8612 - mse: 116.5390 - val_loss: 107.2942 - val_mse: 105.9749\n",
            "Epoch 25/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.7977 - mse: 116.4791 - val_loss: 91.6068 - val_mse: 90.2893\n",
            "Epoch 26/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90.0132 - mse: 88.6970 - val_loss: 75.6728 - val_mse: 74.3605\n",
            "Epoch 27/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.0925 - mse: 63.7808 - val_loss: 64.1198 - val_mse: 62.8115\n",
            "Epoch 28/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.4042 - mse: 69.0971 - val_loss: 60.3844 - val_mse: 59.0799\n",
            "Epoch 29/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.1118 - mse: 55.8084 - val_loss: 48.6326 - val_mse: 47.3316\n",
            "Epoch 30/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.4571 - mse: 55.1562 - val_loss: 42.0057 - val_mse: 40.7057\n",
            "Epoch 31/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.4587 - mse: 40.1591 - val_loss: 37.7654 - val_mse: 36.4669\n",
            "Epoch 32/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.7739 - mse: 39.4761 - val_loss: 32.8569 - val_mse: 31.5617\n",
            "Epoch 33/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.3121 - mse: 47.0172 - val_loss: 28.5182 - val_mse: 27.2239\n",
            "Epoch 34/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.9231 - mse: 38.6299 - val_loss: 28.3502 - val_mse: 27.0590\n",
            "Epoch 35/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.6006 - mse: 33.3097 - val_loss: 25.6899 - val_mse: 24.4008\n",
            "Epoch 36/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1703 - mse: 26.8816 - val_loss: 25.2047 - val_mse: 23.9189\n",
            "Epoch 37/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 28.9178 - mse: 27.6329 - val_loss: 23.4249 - val_mse: 22.1424\n",
            "Epoch 38/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 36.1292 - mse: 34.8477 - val_loss: 22.2129 - val_mse: 20.9341\n",
            "Epoch 39/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9450 - mse: 25.6677 - val_loss: 20.2776 - val_mse: 19.0033\n",
            "Epoch 40/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4235 - mse: 27.1505 - val_loss: 21.1570 - val_mse: 19.8844\n",
            "Epoch 41/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.1385 - mse: 24.8665 - val_loss: 20.3723 - val_mse: 19.1022\n",
            "Epoch 42/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0734 - mse: 19.8033 - val_loss: 19.1854 - val_mse: 17.9175\n",
            "Epoch 43/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5803 - mse: 29.3129 - val_loss: 19.4155 - val_mse: 18.1496\n",
            "Epoch 44/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0692 - mse: 19.8034 - val_loss: 18.6307 - val_mse: 17.3660\n",
            "Epoch 45/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 20.9166 - mse: 19.6525 - val_loss: 17.9850 - val_mse: 16.7238\n",
            "Epoch 46/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.5285 - mse: 17.2686 - val_loss: 17.8604 - val_mse: 16.6036\n",
            "Epoch 47/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.6707 - mse: 21.4147 - val_loss: 17.9467 - val_mse: 16.6932\n",
            "Epoch 48/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 21.0520 - mse: 19.7991 - val_loss: 17.6968 - val_mse: 16.4460\n",
            "Epoch 49/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 19.8702 - mse: 18.6203 - val_loss: 18.7916 - val_mse: 17.5452\n",
            "Epoch 50/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.9333 - mse: 23.6875 - val_loss: 18.1875 - val_mse: 16.9430\n",
            "Epoch 51/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 24.1455 - mse: 22.9021 - val_loss: 17.5064 - val_mse: 16.2658\n",
            "Epoch 52/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.7938 - mse: 24.5543 - val_loss: 17.2760 - val_mse: 16.0391\n",
            "Epoch 53/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6353 - mse: 19.3996 - val_loss: 16.4214 - val_mse: 15.1893\n",
            "Epoch 54/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0307 - mse: 17.7995 - val_loss: 15.8248 - val_mse: 14.5959\n",
            "Epoch 55/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.5376 - mse: 22.3094 - val_loss: 15.2370 - val_mse: 14.0110\n",
            "Epoch 56/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6602 - mse: 19.4350 - val_loss: 15.2024 - val_mse: 13.9793\n",
            "Epoch 57/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.4545 - mse: 17.2317 - val_loss: 15.8937 - val_mse: 14.6706\n",
            "Epoch 58/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9518 - mse: 26.7290 - val_loss: 16.3240 - val_mse: 15.1025\n",
            "Epoch 59/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0487 - mse: 25.8282 - val_loss: 15.3878 - val_mse: 14.1696\n",
            "Epoch 60/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.1031 - mse: 23.8861 - val_loss: 15.2124 - val_mse: 13.9978\n",
            "Epoch 61/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.1139 - mse: 21.9001 - val_loss: 15.2205 - val_mse: 14.0093\n",
            "Epoch 62/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1225 - mse: 19.9115 - val_loss: 15.0389 - val_mse: 13.8310\n",
            "Epoch 63/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.8477 - mse: 22.6410 - val_loss: 15.5767 - val_mse: 14.3728\n",
            "Epoch 64/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.1258 - mse: 17.9225 - val_loss: 14.3641 - val_mse: 13.1643\n",
            "Epoch 65/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.4826 - mse: 24.2832 - val_loss: 14.4220 - val_mse: 13.2242\n",
            "Epoch 66/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0806 - mse: 26.8830 - val_loss: 14.8225 - val_mse: 13.6261\n",
            "Epoch 67/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0863 - mse: 18.8900 - val_loss: 15.1884 - val_mse: 13.9941\n",
            "Epoch 68/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9344 - mse: 17.7420 - val_loss: 15.5070 - val_mse: 14.3173\n",
            "Epoch 69/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.3517 - mse: 16.1627 - val_loss: 15.5448 - val_mse: 14.3587\n",
            "Epoch 70/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.5317 - mse: 23.3462 - val_loss: 15.8119 - val_mse: 14.6279\n",
            "Epoch 71/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.8578 - mse: 30.6742 - val_loss: 15.9795 - val_mse: 14.7979\n",
            "Epoch 72/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0063 - mse: 25.8255 - val_loss: 16.4824 - val_mse: 15.3045\n",
            "Epoch 73/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.0832 - mse: 22.9062 - val_loss: 15.8528 - val_mse: 14.6792\n",
            "Epoch 74/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.8702 - mse: 19.6973 - val_loss: 16.1697 - val_mse: 14.9982\n",
            "Epoch 75/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1294 - mse: 16.9588 - val_loss: 15.2826 - val_mse: 14.1151\n",
            "Epoch 76/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7075 - mse: 19.5410 - val_loss: 15.7192 - val_mse: 14.5548\n",
            "Epoch 77/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.0597 - mse: 16.8955 - val_loss: 15.9480 - val_mse: 14.7868\n",
            "Epoch 78/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.6714 - mse: 29.5111 - val_loss: 15.8539 - val_mse: 14.6947\n",
            "Epoch 79/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.5582 - mse: 17.4000 - val_loss: 15.1167 - val_mse: 13.9612\n",
            "Epoch 80/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8663 - mse: 19.7115 - val_loss: 14.6362 - val_mse: 13.4833\n",
            "Epoch 81/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.0369 - mse: 20.8844 - val_loss: 15.0495 - val_mse: 13.8998\n",
            "Epoch 82/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.6358 - mse: 18.4869 - val_loss: 15.5289 - val_mse: 14.3828\n",
            "Epoch 83/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.5749 - mse: 28.4292 - val_loss: 15.7565 - val_mse: 14.6144\n",
            "Epoch 84/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.2297 - mse: 19.0885 - val_loss: 16.1220 - val_mse: 14.9833\n",
            "Epoch 85/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.2250 - mse: 16.0867 - val_loss: 15.1088 - val_mse: 13.9727\n",
            "Epoch 86/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.6631 - mse: 15.5278 - val_loss: 14.2344 - val_mse: 13.1006\n",
            "Epoch 87/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.3487 - mse: 16.2155 - val_loss: 14.8049 - val_mse: 13.6744\n",
            "Epoch 88/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.9344 - mse: 20.8047 - val_loss: 15.5484 - val_mse: 14.4213\n",
            "Epoch 89/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1212 - mse: 19.9947 - val_loss: 14.9140 - val_mse: 13.7883\n",
            "Epoch 90/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.9908 - mse: 22.8656 - val_loss: 14.6231 - val_mse: 13.4998\n",
            "Epoch 91/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.2178 - mse: 22.0955 - val_loss: 14.6716 - val_mse: 13.5519\n",
            "Epoch 92/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.1432 - mse: 25.0243 - val_loss: 15.4225 - val_mse: 14.3052\n",
            "Epoch 93/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.4011 - mse: 24.2838 - val_loss: 14.4773 - val_mse: 13.3613\n",
            "Epoch 94/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.9521 - mse: 23.8374 - val_loss: 13.8616 - val_mse: 12.7492\n",
            "Epoch 95/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.6458 - mse: 16.5339 - val_loss: 14.3108 - val_mse: 13.1999\n",
            "Epoch 96/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.3475 - mse: 20.2370 - val_loss: 14.2150 - val_mse: 13.1056\n",
            "Epoch 97/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4268 - mse: 19.3182 - val_loss: 14.5979 - val_mse: 13.4922\n",
            "Epoch 98/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.1258 - mse: 16.0208 - val_loss: 16.1011 - val_mse: 14.9982\n",
            "Epoch 99/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6783 - mse: 19.5762 - val_loss: 15.7134 - val_mse: 14.6129\n",
            "Epoch 100/100\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.8032 - mse: 18.7040 - val_loss: 14.7537 - val_mse: 13.6574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78f037dba950>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# compile the neural network and fit it to the data\n",
        "nn.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "\n",
        "nn.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=8, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E77YIG9n1e9y",
        "outputId": "61087a93-8259-404f-9237-92fbb0f6087b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        }
      ],
      "source": [
        "# now get predictions on the test data and mse\n",
        "y_pred = nn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYL9sLOy7B6K",
        "outputId": "c0a6b8cd-547b-40bf-dc4c-50474d8609a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error (neural network): 12.376206224918539\n"
          ]
        }
      ],
      "source": [
        "# it is clear that the neural network performed well but also required the most computational resources\n",
        "# the neural network was able to capture nuances and nonlinearity in the data that the linear regression\n",
        "# may not have been able to. However, AdaBoost with decision trees performed better and was both easier to\n",
        "# write and computationally more efficient than a neural network\n",
        "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
        "print('Mean squared error (neural network):', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NiwAoudpBY-K"
      },
      "outputs": [],
      "source": [
        "def get_avg_nn_mse():\n",
        "  errors = []\n",
        "  for i in range(100):\n",
        "    # need to redefine neural network each time\n",
        "    nn = Sequential()\n",
        "    nn.add(InputLayer((X_train.shape[1],)))\n",
        "    # add a lay with regularization\n",
        "    nn.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
        "    # Batch normalization to normalize the outputs from each hidden layer before passing them along\n",
        "    # Batch normalization ensures that the data distribution remains consistent\n",
        "    nn.add(BatchNormalization())\n",
        "    nn.add(Dense(8, activation='relu'))\n",
        "    nn.add(BatchNormalization())\n",
        "    # linear activation function for output layer in regression\n",
        "    nn.add(Dense(1, activation='linear'))\n",
        "    # fit data and predict values\n",
        "\n",
        "    nn.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "    nn.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=8, verbose=0)\n",
        "    y_pred = nn.predict(X_test)\n",
        "    mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
        "    errors.append(mse)\n",
        "    print(f'Trial {i+1} completed...')\n",
        "  return statistics.mean(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNNMMCYMwDTM",
        "outputId": "e21c6fb4-8718-45f3-f1c3-7138111961fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Trial 1 completed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78f0340b8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78f0340b8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 2 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Trial 3 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Trial 4 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 5 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 6 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Trial 7 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 8 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Trial 9 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 10 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 11 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Trial 12 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 13 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 14 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 15 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 16 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 17 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Trial 18 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 19 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 20 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 21 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Trial 22 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Trial 23 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Trial 24 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 25 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Trial 26 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 27 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 28 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 29 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 30 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 31 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 32 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 33 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 34 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Trial 35 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 36 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 37 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 38 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Trial 39 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Trial 40 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 41 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 42 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 43 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 44 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 45 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 46 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 47 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 48 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Trial 49 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Trial 50 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 51 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Trial 52 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 53 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 54 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 55 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 56 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 57 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 58 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Trial 59 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Trial 60 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 61 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 62 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 63 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 64 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 65 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 66 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Trial 67 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 68 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 69 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 70 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Trial 71 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Trial 72 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 73 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 74 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Trial 75 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 76 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 77 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 78 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 79 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Trial 80 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 81 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 82 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 83 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 84 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 85 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 86 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 87 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Trial 88 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 89 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 90 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Trial 91 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 92 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Trial 93 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 94 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 95 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Trial 96 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 97 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Trial 98 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Trial 99 completed...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Trial 100 completed...\n",
            "The average mse after 100 trials for a neural network: 17.618831730369934\n"
          ]
        }
      ],
      "source": [
        "# get the average mse after 100 trials\n",
        "print('The average mse after 100 trials for a neural network:', get_avg_nn_mse())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "doric",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}